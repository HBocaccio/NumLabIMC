{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HBocaccio/NumLabIMC/blob/main/Colabs/nb06_Reconstrucci%C3%B3nODEs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introducción al modelado continuo** (*a.k.a.* **Ecuaciones de la física matemática**)\n",
        "## Laboratorio numérico 2024\n",
        "\n",
        "Bienvenidos al laboratorio numérico de la materia *Introducción al modelado continuo*, también conocida como *Ecuaciones de la física matemática*. En este, vamos a ver métodos numéricos para resolver distintos tipos de problemas de manera general, y su relación y aplicación a problemas específicos de la materia, de manera tal de complementar los contenidos de la cursada teórico-práctica."
      ],
      "metadata": {
        "id": "Z-0V90NH-R8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Motivación de este colab\n",
        "<!-- $$\\require{amsmath}$$ -->\n",
        "\n",
        "Recordemos que estamos estudiando **sistemas dinámicos**, con reglas representadas por **ecuaciones diferenciales ordinarias (ODEs)**. Hasta ahora, vimos como partiendo de los modelos definidos por estas ecuaciones podemos estudiar un cierto sistema dinámico analizando las características matemáticas que surgen de las ecuaciones que lo describen (o al menos describen ciertas propiedades del fenómeno). Esto incluía la integración de las ecuaciones para encontrar la evolución temporal de las variables. Pero qué pasaría si en lugar de tener el modelo que describe un fenómeno, tenemos sólo la evolución temporal de las variables?\n",
        "\n",
        "En esta clase vamos a ver cómo podemos pensar estrategias para **reconstruir las ecuaciones** que rigen a un sistema dinámico a partir de conocer los valores de las variables para distintos tiempos. Se trata por lo tanto de una estrategia de modelado data-driven, porque vamos a construir un modelo de un sistema dinámico a partir de datos."
      ],
      "metadata": {
        "id": "tpU83zEF-Rzk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it_DdaJ5EY9t"
      },
      "source": [
        "# Reconstrucción de ODEs\n",
        "\n",
        "En este Colab vamos a ver una estrategia de modelado data-driven para encontrar las ecuaciones diferenciales de un sistema a partir de la serie temporal de sus variables. Este Colab es una adaptación de una de las guías de la materia *Sistemas dinamicos e inteligencia artificial aplicado al modelado de datos*:\n",
        "https://materias.df.uba.ar/sdeiaaamdda2021c2/guias/\n",
        "\n",
        "El método de reconstrucción de ODEs a partir de los datos fue propuesto en el siguiente paper:\n",
        "https://www.pnas.org/doi/abs/10.1073/pnas.1517384113\n",
        "\n",
        "Se basa en plantear que las ODEs plantean una relación lineal entre las derivadas de las variables (variables dependientes) y transformaciones de las variables en una base de funciones (variables independientes), como por ejemplo, tener todos los posibles términos polinómicos que combinan variables mediante la multiplicación, hasta un cierto orden. De esta manera, se puede plantear una regresión lineal y estimar los coeficientes que multiplican a las variables transformadas. Si además aplicamos una penalización de tipo LASSO, lo que hace que muchos coeficientes se hagan cero, vamos a obtener una matriz de coeficientes esparsa, y la mayoría de los términos posibles no van a aparecer. Entonces, vamos a obtener un conjunto chico de términos que describen el campo vector, pudiendo reconstruir las ODEs que describen la dinámica del sistema.\n",
        "\n",
        "La única suposición sobre la estructura del modelo es que sólo hay unos pocos términos importantes que gobiernan la dinámica del sistema, de modo que las ecuaciones son esparsas (sobreviven pocos términos debido a que la mayoría de los coeficientes son cero) en el espacio de funciones posibles. Esta suposición se cumple para muchos sistemas físicos en una base apropiada.\n",
        "\n",
        "En el paper de referencia aplican este método a datos simulados del atractor de Lorenz, computan los valores al transformar las variables a una base polinómica, y estiman la matriz de coeficientes de donde reconstruyen las ecuaciones que describen el sistema original. Esto se describe en la siguiente figura:\n",
        "![](https://dt5vp8kor0orz.cloudfront.net/5d150cec2775f9bc863760448f14104cc8f42368/5-Figure1-1.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaaPN7C7kI4r"
      },
      "source": [
        "# Reconstrucción del atractor de Lorenz\n",
        "\n",
        "En esta primera parte, vamos a trabajar en reconstruir las ecuaciones de Lorenz a partir de datos. Para ello, primero vamos a generar un conjunto de datos a partir de integrar el sistema de Lorenz. De esta manera, tendremos una simulación de la evolución temporal de las variables de un atractor de Lorenz. Vamos a considerar que estos son nuestros datos reales, y vamos a usar estos datos para hacer el proceso inverso e inferir las ecuaciones diferenciales que rigen el sistema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b355g8y1RSNW"
      },
      "source": [
        "## Generación de datos simulados\n",
        "\n",
        "Definimos el sistema de Lorenz y simulamos datos como soluciones al sistema obtenidas mediante integración numérica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUfubt34MGyL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lorenz(t, X, sigma=10, r=28, b=8/3):\n",
        "    x, y, z = X\n",
        "    x_dot = sigma * (y - x)\n",
        "    y_dot = r * x - y - x * z\n",
        "    z_dot = x * y - b * z\n",
        "    return [x_dot, y_dot, z_dot]"
      ],
      "metadata": {
        "id": "OPKoXUhSX-OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos un tiempo de integración largo, pero nos quedamos con las últimas soluciones, de manera tal que se haya convergido al atractor."
      ],
      "metadata": {
        "id": "gDCQRJfqasr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = 0.005\n",
        "t_max = 5000\n",
        "t_eval = np.arange(0, t_max, dt)\n",
        "t_span = [t_eval[0], t_eval[-1]]\n",
        "X0 = [5, 0, 10]\n",
        "solucion_lorenz = sp.integrate.solve_ivp(lorenz, t_span, X0, t_eval=t_eval)"
      ],
      "metadata": {
        "id": "6zOANoRCZTLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_steps_total = t_eval.shape[0]\n",
        "x_total, y_total, z_total = solucion_lorenz.y"
      ],
      "metadata": {
        "id": "2HabfTgRaY6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NhDAMWEL9LU"
      },
      "outputs": [],
      "source": [
        "num_steps = int(num_steps_total - num_steps_total*0.2)\n",
        "x, y, z = x_total[-num_steps:], y_total[-num_steps:], z_total[-num_steps:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2U1bYGu-FKs"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Ploteamos las soluciones\n",
        "# Número de puntos a graficar\n",
        "N = 20000\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "ax = plt.axes(projection=\"3d\")\n",
        "ax.plot3D(x[0:N], y[0:N], z[0:N], 'darkcyan', alpha=0.8, lw=0.5)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_zlabel('z')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7GKOQ_GkTW2"
      },
      "source": [
        "## Cálculo de derivadas\n",
        "\n",
        "Para realizar la regresión Lasso precisamos no sólo contar con la serie temporal de las variables, sino también con su derivada temporal. Para calcularla vamos a usar la función `gradient()` de numpy. Pueden encontrar el algoritmo numérico que utiliza para calcularlas [en su documentación](https://numpy.org/doc/stable/reference/generated/numpy.gradient.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKRZiVL5Ny-N"
      },
      "outputs": [],
      "source": [
        "# Computamos las derivadas\n",
        "# Noten que es preciso normalizar multiplicando por el paso temporal\n",
        "x_deriv = np.gradient(x) * (1.0/dt)\n",
        "y_deriv = np.gradient(y) * (1.0/dt)\n",
        "z_deriv = np.gradient(z) * (1.0/dt)\n",
        "\n",
        "# Lo unimos en una única matriz con el shape adecuado\n",
        "mat_derivadas = np.asarray([x_deriv, y_deriv, z_deriv]).T\n",
        "print(mat_derivadas.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos las variables y sus derivadas."
      ],
      "metadata": {
        "id": "a2auyLq8b-To"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msBMK1Ek-FKu"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (10, 6))\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(x[0:N])\n",
        "plt.ylabel('x', fontsize=12)\n",
        "plt.subplot(3,1,2)\n",
        "plt.plot(y[0:N])\n",
        "plt.ylabel('y', fontsize=12)\n",
        "plt.subplot(3,1,3)\n",
        "plt.plot(z[0:N])\n",
        "plt.ylabel('z', fontsize=12)\n",
        "plt.xlabel('t', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOC8NHbB-FKu"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (10, 6))\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(x_deriv[0:N])\n",
        "plt.ylabel('$\\dot{x}$', fontsize=12)\n",
        "plt.subplot(3,1,2)\n",
        "plt.plot(y_deriv[0:N])\n",
        "plt.ylabel('$\\dot{y}$', fontsize=12)\n",
        "plt.subplot(3,1,3)\n",
        "plt.plot(z_deriv[0:N])\n",
        "plt.ylabel('$\\dot{z}$', fontsize=12)\n",
        "plt.xlabel('t', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HijdrTB6IUqc"
      },
      "source": [
        "## Base de funciones\n",
        "\n",
        "Además de las derivadas, también precisamos acomodar en la matriz `theta` los términos polinómicos que vamos a utilizar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcTczRa3Q7Ux"
      },
      "outputs": [],
      "source": [
        "# Definimos la matriz vacía\n",
        "theta = np.zeros((x.shape[0], 10))\n",
        "\n",
        "# Completamos con los términos correspondientes\n",
        "theta[:,0] = np.ones_like(x)\n",
        "theta[:,1] = x\n",
        "theta[:,2] = y\n",
        "theta[:,3] = z\n",
        "theta[:,4] = x*x\n",
        "theta[:,5] = x*y\n",
        "theta[:,6] = x*z\n",
        "theta[:,7] = y*y\n",
        "theta[:,8] = y*z\n",
        "theta[:,9] = z*z\n",
        "\n",
        "# Para luego comparar con los resultados obtenidos, definimos estas listas\n",
        "terminos = ['1','x','y','z','xx','xy','xz','yy','yz','zz']\n",
        "real_x_coef = [0,-10,10,0,0,0,0,0,0,0]\n",
        "real_y_coef = [0,28,-1.0,0,0,0,-1.0,0,0,0]\n",
        "real_z_coef = [0,0,0,-2.67,0,1.0,0,0,0,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd_T0DfT69mC"
      },
      "source": [
        "**Observación:** Realizamos el cálculo de los atributos polinómicos de manera manual para transparentar el proceso. Pero existen soluciones de librerías, como `PolynomialFeatures` de `sklearn`, que lo realizan de manera automática (cosa que puede resultar muy cómoda, en especial para órdenes más altos)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2nv1JwskeVE"
      },
      "source": [
        "## Reconstrucción de las ecuaciones con regresión Lasso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVeoL9_AR4uZ"
      },
      "source": [
        "Sabemos que el sistema de ecuaciones que buscamos cuenta con una cantidad limitada de términos no nulos. Para evitar que se activen muchos términos en las ecuaciones, utilizamos la técnica de regularización de tipo **LASSO** o **$L_1$** para la regresión. Esto lo hacemos agregando un término de penalización a la función costo a minimizar, que sea la suma de los módulos de los valores de los coeficientes del modelo, multiplicados por un factor de penalización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7--tviBPUXSN"
      },
      "source": [
        "La librería Scikit-Learn cuenta varias implementaciones de este tipo de regresiones lineales con regularización. Primero vamos a utilizar la regresión Lasso clásica, [aquí su documentación](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgakZT2vRiN_"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "# Definimos el modelo\n",
        "lasso = linear_model.Lasso(alpha=0.2, max_iter=100000, fit_intercept=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV4kCIcGj4Kp"
      },
      "source": [
        "Noten que, al definir la matriz `theta`, agregamos una columna de unos como primera columna. De esta forma, el primer coeficiente de cada ecuación corresponde al término independiente de la misma. Es por esto que debemos setear `fit_intercept=False` al definir el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKK2-YZhj2N6"
      },
      "outputs": [],
      "source": [
        "# Realizamos el ajuste\n",
        "lasso.fit(theta, mat_derivadas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcf69MITmug0"
      },
      "source": [
        "Inspeccionemos el valor numérico de los resultados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RbSQmiXmatz"
      },
      "outputs": [],
      "source": [
        "print('Coeficientes en x:')\n",
        "print(lasso.coef_[0,:])\n",
        "print('\\n')\n",
        "print('Coeficientes en y:')\n",
        "print(lasso.coef_[1,:])\n",
        "print('\\n')\n",
        "print('Coeficientes en z:')\n",
        "print(lasso.coef_[2,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6DMUksu-FKy"
      },
      "outputs": [],
      "source": [
        "print('Coeficientes reales en x:')\n",
        "print(real_x_coef)\n",
        "print('\\n')\n",
        "print('Coeficientes reales en y:')\n",
        "print(real_y_coef)\n",
        "print('\\n')\n",
        "print('Coeficientes reales en z:')\n",
        "print(real_z_coef)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phbj7e0zVuwX"
      },
      "source": [
        "Para comparar los resultados obtenidos con los coeficientes originales, vamos a graficarlos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-T66zjiXGqr"
      },
      "outputs": [],
      "source": [
        "rango = np.arange(len(lasso.coef_[0,:]))\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1,3,1)\n",
        "plt.scatter(rango,real_x_coef, label='Real',s=100)\n",
        "plt.scatter(rango,lasso.coef_[0,:], label='Ajuste',s=100,marker=\"P\")\n",
        "plt.xticks(rango, terminos)\n",
        "plt.xlabel('Coeficientes dx/dt')\n",
        "plt.ylabel('Valor')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.subplot(1,3,2)\n",
        "plt.scatter(rango,real_y_coef, label='Real',s=100)\n",
        "plt.scatter(rango,lasso.coef_[1,:], label='Ajuste',s=100,marker=\"P\")\n",
        "plt.xticks(rango, terminos)\n",
        "plt.xlabel('Coeficientes dy/dt')\n",
        "plt.ylabel('Valor')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.subplot(1,3,3)\n",
        "plt.scatter(rango,real_z_coef, label='Real',s=100)\n",
        "plt.scatter(rango,lasso.coef_[2,:], label='Ajuste',s=100,marker=\"P\")\n",
        "plt.xticks(rango, terminos)\n",
        "plt.xlabel('Coeficientes dz/dt')\n",
        "plt.ylabel('Valor')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.subplots_adjust(wspace=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvwoCLc3V8We"
      },
      "source": [
        "**Discutir:**\n",
        "\n",
        "*   ¿Sobrevivieron únicamente los términos originales?\n",
        "*   Observando el valor de los coeficientes en los términos que se corresponden con los de las ecuaciones originales, ¿Nota alguna particularidad?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX08xjczodlo"
      },
      "source": [
        "Una pregunta interesante para hacerse es: **¿Cómo elegir el hiperparámetro alpha (factor de penalización)?**\n",
        "\n",
        "No hay un valor óptimo universal para el hiperparámetro alpha, depende del dataset con el que estemos trabajando. Recuerden que normalmente no vamos a tener las ecuaciones reales para contrastar (de hecho estas ecuaciones son precisamente lo que estamos buscando).\n",
        "\n",
        "Una forma válida de elegir el hiperparámetro es definir el número máximo de términos que pretendemos que aparezcan en nuestras ecuaciones. Pero, siendo que no conocemos la cantidad mínima de términos relevantes, esta decisión resulta arbitraria.\n",
        "\n",
        "Otra forma es entrenar el modelo para distintos valores de alpha y evaluar la performance del modelo sobre un set distinto al de entrenamiento (test set). Esperamos que el modelo encontrado con el valor mas adecuado de alpha generalice mejor a los datos de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b46TBg6imtfP"
      },
      "outputs": [],
      "source": [
        "# Generamos un vector con los valores de alpha a explorar\n",
        "alphas = np.logspace(-4, 1, 20)\n",
        "print(alphas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmCD_7aTX46r"
      },
      "source": [
        "Separamos los datos en un set de entrenamiento y uno de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7HejR0xx7ri"
      },
      "outputs": [],
      "source": [
        "# Proporción entre train y test\n",
        "proporcion = 0.8\n",
        "\n",
        "# Índice de separación entre train y test\n",
        "indice_test = int(proporcion * num_steps)\n",
        "\n",
        "# Separamos la matriz Theta en 2 partes, una para el train set y otra para el test set.\n",
        "theta_train = theta[:indice_test]\n",
        "theta_test = theta[indice_test:]\n",
        "\n",
        "# Hacemos lo mismo con las derivadas\n",
        "x_deriv_train = x_deriv[:indice_test]\n",
        "x_deriv_test = x_deriv[indice_test:]\n",
        "y_deriv_train = y_deriv[:indice_test]\n",
        "y_deriv_test = y_deriv[indice_test:]\n",
        "z_deriv_train = z_deriv[:indice_test]\n",
        "z_deriv_test = z_deriv[indice_test:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqOCcNY_X-pi"
      },
      "source": [
        "**Atención:** Por una cuestión de simplicidad y velocidad, vamos a realizar el análisis solo para la ecuación correspondiente a la variable $x$. Pero el mismo análisis puede aplicarse a todo el sistema completo.\n",
        "\n",
        "Para cada valor de alpha, entrenamos un modelo sobre el training set y lo evaluamos en el test set (en términos del `mean_squared_error` y del `mean_absolute_error`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGgGW6K1x-U6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Preparamos las listas donde vamos a guardar los datos\n",
        "errores_absolute = []\n",
        "errores_squared = []\n",
        "coeficientes = []\n",
        "\n",
        "# Recorremos los distintos valores de alpha\n",
        "for value in alphas:\n",
        "    print('Calculando con alpha = ', value)\n",
        "    lasso = linear_model.Lasso(alpha=value, max_iter=100000, fit_intercept=False)\n",
        "    lasso.fit(theta_train, x_deriv_train)\n",
        "    x_deriv_test_predict = lasso.predict(theta_test)\n",
        "\n",
        "    # Guardamos los coeficientes encontrados\n",
        "    coeficientes.append(lasso.coef_)\n",
        "\n",
        "    # Computamos el error cometido con 2 métricas distintas\n",
        "    error_absolute = mean_absolute_error(x_deriv_test_predict, x_deriv_test)\n",
        "    error_squared = mean_squared_error(x_deriv_test_predict, x_deriv_test)\n",
        "\n",
        "    # Guardamos el error\n",
        "    errores_absolute.append(error_absolute)\n",
        "    errores_squared.append(error_squared)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3cnJ7ZjdXX6"
      },
      "source": [
        "Grafiquemos el error en función del parámetro alpha. Hacemos un zoom dentro del gráfico para ver los errores más de cerca."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5m5SzEb3Gxv"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
        "fig = plt.figure(figsize = (5,5))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "inset_axes = inset_axes(ax,\n",
        "                    width=\"40%\",\n",
        "                    height=1.8,\n",
        "                    loc=2)\n",
        "ax.semilogx(alphas, errores_absolute, label='Error Absoluto', lw=2)\n",
        "ax.semilogx(alphas, errores_squared, label='Error Cuadrático', lw=2)\n",
        "ax.set_ylabel('Mean Absolute Error - Test set', fontsize=16)\n",
        "ax.set_xlabel('Alpha', fontsize=16)\n",
        "ax.grid(True)\n",
        "ax.legend(loc='upper right')\n",
        "\n",
        "inset_axes.semilogx(alphas, errores_absolute, label='Error Absoluto', lw=1)\n",
        "inset_axes.semilogx(alphas, errores_squared, label='Error Cuadrático', lw=1)\n",
        "inset_axes.set_ylim(0,1)\n",
        "# inset_axes.set_xlim(5e-4,5e-1)\n",
        "inset_axes.set_ylabel('MAE - Test set', fontsize=11)\n",
        "inset_axes.set_xlabel('Alpha', fontsize=11)\n",
        "inset_axes.grid(True)\n",
        "\n",
        "for axis in ['top','bottom','left','right']:\n",
        "    ax.spines[axis].set_linewidth(1.5)\n",
        "    inset_axes.spines[axis].set_linewidth(1.2)\n",
        "ax.tick_params(width=2)\n",
        "ax.tick_params(labelsize=16)\n",
        "\n",
        "inset_axes.yaxis.set_ticks_position('right')\n",
        "inset_axes.yaxis.set_label_position('right')\n",
        "ax.tick_params(width=2)\n",
        "ax.tick_params(labelsize=16)\n",
        "inset_axes.tick_params(width=1.2)\n",
        "inset_axes.tick_params(labelsize=10)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_Kmc15reFqZ"
      },
      "source": [
        "**Ejercicio:** ¿Qué valor de alpha eligirían? Recuerden que, por lo general, un parámetro alpha más grande corresponde a un modelo más simple, con menos términos no nulos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrXqLdWdeILH"
      },
      "source": [
        "Por último vamos a graficar cómo varían los coeficientes a medida que variamos el valor de regularización."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nt7l4Uev5F7t"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "coef_mat = np.asarray(coeficientes).T\n",
        "for i in range(coef_mat.shape[0]):\n",
        "    ter = terminos[i]\n",
        "    plt.semilogx(alphas,coef_mat[i],label=ter)\n",
        "plt.ylabel('Valor del coeficiente', fontsize=12)\n",
        "plt.xlabel('Alpha', fontsize=12)\n",
        "plt.grid(True)\n",
        "# plt.ylim(-0.05,0.05) # Luego descomenten esta linea para hacer zoom\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwPaSTu6kxaX"
      },
      "source": [
        "### Ejercicio 1\n",
        "\n",
        "Repita el proceso realizado, pero esta vez para la ecuación correspondiente a la variable $z$."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # # COMPLETAR"
      ],
      "metadata": {
        "id": "pYkYNDBYlYEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrxSsfi62GyO"
      },
      "source": [
        "**Observación:**\n",
        "\n",
        "*  Una vez que encontaron cuáles son los términos que sobreviven en el valor de alpha óptimo, una buena estrategia podría ser volver a realizar una regresión, pero esta vez utilizando únicamente estos términos y reduciendo (o directamente anulando) el peso de la regularización (alpha). Este proceso normalmente mejora el valor de los coeficientes obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrErru7XvJ3t"
      },
      "source": [
        "## Reconstrucción de las ecuaciones con Sindy\n",
        "\n",
        "Sindy es una librería de python dedicada a la identificación de sistemas dinámicos a partir de datos. La librería contiene varias utilizades dedicadas a este fin, entre ellas podemos destacar:\n",
        "*   Distintos tipos de *sparse regressions*.\n",
        "*   Funciones para computar atributos extras (variables transformadas).\n",
        "*   Funciones para computar derivadas de señales.\n",
        "\n",
        "La característica más importante de la librería es un tipo de regresión llamada **Sequentially thresholded least squares** ([Aqui su código](https://pysindy.readthedocs.io/en/latest/_modules/pysindy/optimizers/stlsq.html)). Este algoritmo es muy parecido al proceso que realizamos en la sección anterior pero con la diferencia que usa una regularización tipo Ridge (la penalización que se agrega a la función costo tiene los coeficientes elevados al cuadrado) y que el algoritmo va *apagando* automáticamente los términos inferiores a cierto *threshold*."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pysindy"
      ],
      "metadata": {
        "id": "acvqaMBinWos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHAPTML_LMl9"
      },
      "source": [
        "Los submódulos de PySINDy están alineados con uno de los términos de la ecuación de aproximación antes mencionada\n",
        "\n",
        "$$ \\dot X \\approx \\Theta(X)\\Xi. $$\n",
        "\n",
        "* `pysindy.differentiate` realiza una diferenciación numérica para calcular $\\dot X$ a partir de $X$;\n",
        "* `pysindy.feature_library` permite al usuario especificar un conjunto de funciones de biblioteca y maneja la formación de $\\Theta(X)$;\n",
        "* `pysindy.optimizers` proporciona un conjunto de solucionadores de regresión LASSO para determinar $\\Xi$.\n",
        "\n",
        "El objeto `SINDy` encapsula un objeto de clase de cada uno de estos tres submódulos y los utiliza, junto con una matriz de datos proporcionada por el usuario, para encontrar un sistema dinámico gobernante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH-vu2RCQTlv"
      },
      "source": [
        "La principal ventaja de utilizar esta librería es la simplicidad con la que se puede implementar la regresión. Noten que, a diferencia de lo que hicimos en la sección anterior, la librería calcula las derivadas y los términos polinómicos automáticamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVbI7ztDvSBq"
      },
      "outputs": [],
      "source": [
        "import pysindy as ps\n",
        "\n",
        "# Hiperparámetros\n",
        "poly_order = 2\n",
        "threshold = 0.05\n",
        "alpha=0.1\n",
        "\n",
        "# Definición del modelo\n",
        "model = ps.SINDy(\n",
        "    # Elegimos el optimizador a utilizar\n",
        "    optimizer=ps.STLSQ(threshold=threshold,alpha=alpha),\n",
        "    # Elegimos los features (términos de las ecuaciones) a utilizar\n",
        "    feature_library=ps.PolynomialLibrary(degree=poly_order),\n",
        "    # Le ponemos un nombre a las variables\n",
        "    feature_names = ['x', 'y', 'z']\n",
        ")\n",
        "\n",
        "# Adecuamos nuestros datos en la matriz 'data'\n",
        "data = np.asarray([x,y,z]).T\n",
        "\n",
        "# En la primer dimensión van los pasos temporales y en la segunda las varables\n",
        "print(data.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym5FYKPsQ_X_"
      },
      "source": [
        "Finalmente entrenamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5b1NxBQQv9T"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento\n",
        "model.fit(data, t=dt)\n",
        "model.print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd44RLsWROt4"
      },
      "source": [
        "Noten que los términos que sobrevivieron en las ecuaciones son los correctos y, además, los valores numéricos de los coeficientes encontrados son increíblemente cercanos a los del sistema original!\n",
        "\n",
        "Por último, podemos usar la misma librería para integrar el modelo encontrado y comparar las soluciones con las del sistema original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6f1Cq8YR9KQ"
      },
      "outputs": [],
      "source": [
        "# Definimos el vector de tiempos\n",
        "tiempos = np.arange(0, 100, dt)\n",
        "# Integramos el sistema encontrado durante ese tiempo\n",
        "data_sim = model.simulate(data[0], tiempos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHcYPo2RSepl"
      },
      "outputs": [],
      "source": [
        "# Graficamos las soluciones\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "ax = plt.axes(projection=\"3d\")\n",
        "ax.plot3D(data_sim[:,0], data_sim[:,1], data_sim[:,2], alpha=0.85)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_zlabel('z')\n",
        "plt.title('Lorenz de las ecuaciones encontradas')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3erJh5KMIMQ9"
      },
      "source": [
        "# Reconstrucción del oscilador de relajación de Van Der Pol\n",
        "\n",
        "Siendo que funcionaron tan bien en un atractor caótico, a esta altura resulta muy tentador pensar que esta clase de métodos funcionarán bien en cualquier tipo de sistemas.\n",
        "\n",
        "Probemos con datos simulados a partir del sistema:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck0AuVru9tDh"
      },
      "outputs": [],
      "source": [
        "def van_der_pol(t, X, mu=7.0):\n",
        "    x, y = X\n",
        "    x_dot = y\n",
        "    y_dot = mu * (1 - x * x) * y - x\n",
        "    return [x_dot, y_dot]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = 0.4\n",
        "t_max = 500\n",
        "t_eval = np.arange(0, t_max, dt)\n",
        "t_span = [t_eval[0], t_eval[-1]]\n",
        "X0 = [-2, 0]\n",
        "solucion_vanderpol = sp.integrate.solve_ivp(van_der_pol, t_span, X0, t_eval=t_eval, args=(7,))\n",
        "x, y = solucion_vanderpol.y"
      ],
      "metadata": {
        "id": "vNBg1QyBruhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-KwkigaF2Vm"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(x, y, 'o')\n",
        "plt.xlabel('x', fontsize=12)\n",
        "plt.ylabel('y', fontsize=12)\n",
        "plt.title('Diagrama de Fases', fontsize=12)\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(t_eval[:100], x[:100], '-o')\n",
        "plt.xlabel('Tiempo', fontsize=12)\n",
        "plt.ylabel('x', fontsize=12)\n",
        "plt.title('Evolucion de x(t)', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVNkE6nQKEoF"
      },
      "source": [
        "Este es un oscilador de relajación muy popular llamado oscilador de **Van Der Pol**, cuyas ecuaciones son:\n",
        "\n",
        "$$\n",
        "\t\\begin{bmatrix} \\frac{dx}{dt} \\\\ \\frac{dy}{dt} \\end{bmatrix}\n",
        "\t= \\begin{bmatrix} y \\\\ -x + \\mu y - \\mu x^2y  \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "La dinámica en este caso no es muy compleja: un único término cúbico y 3 términos lineales dan lugar a una solución de tipo ciclo limite.\n",
        "\n",
        "Además, contamos con más de 20 samples por cada oscilación y ni siquiera estamos agregando ruido. Si pensamos en un escenario experimental, este sería un caso prácticamente ideal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Vamos a hacer el siguiente análisis:**\n",
        "\n",
        "*   Probemos de usar el método para reconstruir las ODEs y exploremos los resultados obtenidos para este simple sistema dinámico.\n",
        "\n",
        "*   ¿Coinciden los términos encontrados con los del sistema original? ¿Son cualitativamente similares las soluciones?\n",
        "\n",
        "*   ¿Cuál les parece que puede ser la causa de este desempeño?\n",
        "\n",
        "*   Cambiemos el valor del parámetro $\\mu$ en la función `val_der_pol()` de $\\mu = 7$ a $\\mu = 1$ y volvamos a realizar el ejercicio. ¿Mejora o empeora la capacidad de reproducir las ecuaciones del sistema? ¿Qué cambió?"
      ],
      "metadata": {
        "id": "h7qdMS7rtJf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssh_QHgt_2XE"
      },
      "outputs": [],
      "source": [
        "import pysindy as ps\n",
        "\n",
        "# Hiperparámetros\n",
        "poly_order = 3\n",
        "threshold = 0.05\n",
        "alpha=0.1\n",
        "\n",
        "# Definición del modelo\n",
        "model = ps.SINDy(\n",
        "    optimizer=ps.STLSQ(threshold=threshold,alpha=alpha),\n",
        "    feature_library=ps.PolynomialLibrary(degree=poly_order,include_bias=True),\n",
        "    feature_names = ['x', 'y']\n",
        ")\n",
        "\n",
        "data = np.asarray([x,y]).T\n",
        "\n",
        "# En la primera dimensión van los pasos temporales y en la segunda las varables\n",
        "print(data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVSAFvrJBKvt"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento\n",
        "model.fit(data, t=dt)\n",
        "model.print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFn-6l4_LQCF"
      },
      "source": [
        "Si graficamos las soluciones del sistema encontrado contra las del sistema original:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tiempos = np.arange(0, 100, dt)\n",
        "data_sim = model.simulate(data[0], tiempos)"
      ],
      "metadata": {
        "id": "6SQ_8N48uNtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_sim = data_sim[:,0]\n",
        "y_sim = data_sim[:,1]"
      ],
      "metadata": {
        "id": "myyRcBzoxVo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik5OaXnJLVki"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(x, y, 'o')\n",
        "plt.plot(x_sim, y_sim, 'o')\n",
        "plt.xlabel('x', fontsize=12)\n",
        "plt.ylabel('y', fontsize=12)\n",
        "plt.title('Diagrama de Fases', fontsize=12)\n",
        "plt.xlim(-2.5,2.5)\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(t_eval[:100], x[:100], '-o')\n",
        "plt.plot(t_eval[:100], x_sim[:100], '-o')\n",
        "plt.xlabel('Tiempo', fontsize=12)\n",
        "plt.ylabel('x', fontsize=12)\n",
        "plt.title('Evolucion de x(t)', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evi13GVB-FLM"
      },
      "source": [
        "Con $\\mu = 1$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDxP22_1-FLN"
      },
      "outputs": [],
      "source": [
        "dt = 0.4\n",
        "t_max = 500\n",
        "t_eval = np.arange(0, t_max, dt)\n",
        "t_span = [t_eval[0], t_eval[-1]]\n",
        "X0 = [-2, 0]\n",
        "solucion_vanderpol = sp.integrate.solve_ivp(van_der_pol, t_span, X0, t_eval=t_eval, args=(1,))\n",
        "x, y = solucion_vanderpol.y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qQ5_oiU-FLN"
      },
      "outputs": [],
      "source": [
        "import pysindy as ps\n",
        "\n",
        "# Hiperparámetros\n",
        "poly_order = 3\n",
        "threshold = 0.05\n",
        "alpha=0.1\n",
        "\n",
        "# Definición del modelo\n",
        "model = ps.SINDy(\n",
        "    optimizer=ps.STLSQ(threshold=threshold,alpha=alpha),\n",
        "    feature_library=ps.PolynomialLibrary(degree=poly_order,include_bias=True),\n",
        "    feature_names = ['x', 'y']\n",
        ")\n",
        "\n",
        "data = np.asarray([x,y]).T\n",
        "# En la primera dimensión van los pasos temporales y en la segunda las varables\n",
        "print(data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_FyXc_w-FLN"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento\n",
        "model.fit(data, t=dt)\n",
        "model.print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tiempos = np.arange(0, 100, dt)\n",
        "data_sim = model.simulate(data[0], tiempos)\n",
        "x_sim = data_sim[:,0]\n",
        "y_sim = data_sim[:,1]"
      ],
      "metadata": {
        "id": "j3mUlwumzPmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEA_HI2y-FLN"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(x, y, 'o')\n",
        "plt.plot(x_sim, y_sim, 'o')\n",
        "plt.xlabel('x', fontsize=12)\n",
        "plt.ylabel('y', fontsize=12)\n",
        "plt.title('Diagrama de Fases', fontsize=12)\n",
        "plt.xlim(-2.5,2.5)\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(t_eval[:100], x[:100], '-o')\n",
        "plt.plot(t_eval[:100], x_sim[:100], '-o')\n",
        "plt.xlabel('Tiempo', fontsize=12)\n",
        "plt.ylabel('x', fontsize=12)\n",
        "plt.title('Evolucion de x(t)', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consideraciones de la derivada numérica\n",
        "\n",
        "Como vimos, el método permite reconstruir las ecuaciones haciendo una regresión entre las derivadas y las variables transformadas. Esto es posible aún cuando no tengamos las derivadas como dato, haciendo derivación numérica. No obstante, como vimos en la 2da clase, la derivada numérica puede ser muy sensible o ruidosa o en todo caso requiere de especial cuidado. Los métodos habituales de diferencias finitas tienden a amplificar mucho el ruido presente en los datos. Tal es así, que SINDy usa un método de derivación regularizada llamado *Total Variation Regularized Numerical Differentiation (TVRegDiff)*, que le permite obtener derivadas numéricas más suaves. Pueden encontrar una descripción del problema y el método en https://oliver-k-ernst.medium.com/how-to-differentiate-noisy-signals-2baf71b8bb65, o en la publicación original https://onlinelibrary.wiley.com/doi/10.5402/2011/164564.\n",
        "\n",
        "Aún usando esta forma regularizada de cálculo numérico de la derivada, sigue siendo un tema que se debe abordar con criterio cuando se reconstruyen ODEs. De hecho, el problema que estamos encontrando para el oscilador de relajación con $\\mu=7$ justamente se debe a que la derivada tiene cambios muy bruscos, como habrán notado.\n",
        "\n",
        "Veamos cómo son las soluciones y sus derivadas numéricas (usando np.gradient) para $\\mu=1$ y $\\mu=7$."
      ],
      "metadata": {
        "id": "XuwBmw5V78Qn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-I3gMa_-FLO"
      },
      "outputs": [],
      "source": [
        "solucion_vanderpol_mu7 = sp.integrate.solve_ivp(van_der_pol, t_span, X0, t_eval=t_eval, args=(7,))\n",
        "x_mu7, y_mu7 = solucion_vanderpol_mu7.y\n",
        "solucion_vanderpol_mu1 = sp.integrate.solve_ivp(van_der_pol, t_span, X0, t_eval=t_eval, args=(1,))\n",
        "x_mu1, y_mu1 = solucion_vanderpol_mu1.y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEop4XOb-FLO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(t_eval[:100], x_mu1[:100], '-o', label='mu = 1')\n",
        "plt.plot(t_eval[:100], x_mu7[:100], '-o', label='mu = 7')\n",
        "plt.xlabel('Tiempo', fontsize=12)\n",
        "plt.ylabel('x', fontsize=12)\n",
        "plt.title('Evolucion de x(t)', fontsize=12)\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(t_eval[:100], np.gradient(x_mu1)[:100], '-o', label='mu = 1')\n",
        "plt.plot(t_eval[:100], np.gradient(x_mu7)[:100], '-o', label='mu = 7')\n",
        "plt.xlabel('Tiempo', fontsize=12)\n",
        "plt.ylabel('$\\dot{x}$', fontsize=12)\n",
        "plt.title('Derivada de x(t)', fontsize=12)\n",
        "plt.legend()\n",
        "plt.subplots_adjust(wspace=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En particular, SINDy usa el paquete `derivative` (https://derivative.readthedocs.io/en/latest/) para calcular la derivada con TVRegDiff, y el hiperparámetro `alpha` es el que define la regularización en el cálculo de la derivada. Un valor muy chico dará una solución muy fiel a la señal original, pero que puede ser muy ruidosa. En cambio, un valor muy grande dará una derivada que será menos fiel a la señal original. Se debe entonces encontrar un valor óptimo de acuerdo al balance que se quiera lograr entre supresión de oscilaciones y fidelidad a los datos, que dependerá del problema particular. No obstante, no siempre se puede encontrar una situación ideal cuando el problema está mal condicionado, por ejemplo por estar fuertemente subsampleado."
      ],
      "metadata": {
        "id": "xUQ_CQ2MDqL4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 2 [Extra]\n",
        "\n",
        "Para probar el efecto del alpha, pruebe de simular datos de la función $f(t) = |t - 1/2|$, evaluando en 100 valores de $t$ equidistantes dentro del intervalo [0, 1], y agregando ruido gaussiano de desvío estándar 0.05. Compute las derivadas para distintos valores de alpha, usando el método que usa SINDy (debería ser `ps.differentiation.sindy_derivative.dxdt(f, t, kind='trend_filtered', order=0, alpha=alpha)`). Qué observa?"
      ],
      "metadata": {
        "id": "tBD61nYOLc2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 3 [Extra]\n",
        "\n",
        "Pruebe de modificar los parámetros alpha y thresholds para ver si puede mejorar la reconstrucción de las ODEs en el oscilador de relajación."
      ],
      "metadata": {
        "id": "vI78EGAVJFcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 4 [Extra Extra]\n",
        "\n",
        "Vean también otras opciones de derivación numérica."
      ],
      "metadata": {
        "id": "T2cbtZlhKxxf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "79LiNxtwIyHe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}