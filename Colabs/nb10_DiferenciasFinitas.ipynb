{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HBocaccio/NumLabIMC/blob/main/Colabs/nb10_DiferenciasFinitas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introducción al modelado continuo** (*a.k.a.* **Ecuaciones de la física matemática**)\n",
        "## Laboratorio numérico 2024\n",
        "\n",
        "Bienvenidos al laboratorio numérico de la materia *Introducción al modelado continuo*, también conocida como *Ecuaciones de la física matemática*. En este, vamos a ver métodos numéricos para resolver distintos tipos de problemas de manera general, y su relación y aplicación a problemas específicos de la materia, de manera tal de complementar los contenidos de la cursada teórico-práctica."
      ],
      "metadata": {
        "id": "uh1VJKik0NBR"
      },
      "id": "uh1VJKik0NBR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Motivación de este colab\n",
        "\n",
        "En el 1er eje temático de la materia vimos ecuaciones diferenciales ordinarias (ODEs), que describían la dinámica de variables continuas que dependían sólo del tiempo, es decir, cada una de las variables podía representarse con una función univariada (depende de una única variable). De esta manera, las ODEs que describían un sistema autónomo (el tiempo no aparece explícitamente en la ecuación) se escribían como $\\dot{\\vec{x}}(t) = \\vec{f}(\\vec{x})$. En el caso más simple, el 1D, teníamos una única variable descrita por una única ODE:\n",
        "\n",
        "$$\n",
        "\\dot{x}(t) = f(x)\n",
        "$$\n",
        "\n",
        "Este sistema los podíamos resolver integrando numéricamente de manera tal de obtener la solución $x(t)$ en el marco de los problemas de valores iniciales.\n",
        "\n",
        "En este eje temático vamos a abordar un problema distinto, que consiste en tener variables continuas que se representan como funciones multivariadas $u(x,t)$. De esta manera, la derivada respecto de una de sus variables ya no es la derivada total, si no que es una derivada parcial. Ahora las reglas que describen la evolución temporal de estas variables ya no son ODEs, si no que son **ecuaciones en derivadas parciales** (PDEs), que son básicamente ecuaciones que relacionan funciones multivariadas y sus derivadas parciales. La resolución de este tipo de sistemas se encuadra en el marco de problemas de condiciones de borde, siendo un caso particular la consideración de condiciones iniciales cuando una de las variables es el tiempo.\n",
        "\n",
        "Las PDEs son fundamentales en muchas áreas de la física y las matemáticas aplicadas, describiendo muchísimos fenómenos diversos. La resolución de estos sistemas se vuelve altamente no trivial, debiendo recurrir a distintas estrategias matemáticas (como las vistas en la teórica) y numéricas. En este colab vamos a definir y explorar el **método de diferencias finitas**, que nos va a permitir resolver PDEs numéricamente, siendo especialmente útil cuando las soluciones analíticas no son posibles."
      ],
      "metadata": {
        "id": "LwSLgS200ZMd"
      },
      "id": "LwSLgS200ZMd"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "oKHiS-xPJjj1"
      },
      "id": "oKHiS-xPJjj1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Ecuaciones diferenciales\n",
        "\n",
        "Una ecuación diferencial es una ecuación que implica variables, funciones de variables, y combinaciones de sus derivadas. De manera general, se pueden describir de la siguiente forma:\n",
        "\n",
        "$$\n",
        "\\mathcal{D}[u(x)] = g(x), \\quad x \\in [a, b],\n",
        "$$\n",
        "\n",
        "donde $\\mathcal{D}$ es un operador diferencial que aplica una combinación de derivadas (por ejemplo, $\\mathcal{D}[u] = u'$ o $\\mathcal{D}[u] = u''$) y $g(x)$ es un término fuente o función conocida. Este problema se resuelve sujeto a condiciones de contorno en los extremos $x_1 = a$ y $x_N = b$, es decir a imposiciones sobre los valores de $u$ o sus derivadas, como por ejemplo $u(x_1) = \\alpha$ o $u'(x_N) = \\delta$.\n",
        "\n",
        "Por lo tanto, resulta relevante explorar métodos numéricos para aproximar derivadas, como es el método de diferencias finitas, de manera tal de poder resolver la ecuación diferencial asociada a un problema.\n"
      ],
      "metadata": {
        "id": "Zm5jko79lBNi"
      },
      "id": "Zm5jko79lBNi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Método de Diferencias Finitas\n",
        "\n",
        "El método de diferencias finitas es un método que ya nombramos en el Colab de la clase de derivación numérica. En esa clase, básicamente aproximábamos las derivadas primeras por el cociente incremental, para obtener la derivada hacia adelante. Pero vimos que esto podía pensarse de manera generalizada a partir del desarrollo de Taylor de la función, para obtener las [fórmulas de diferencias finitas](https://en.wikipedia.org/wiki/Finite_difference#Forward,_backward,_and_central_differences).\n",
        "\n",
        "Para una función $u(x)$, la derivada primera, que se puede expresar con la notación $\\frac{d u(x)}{d x} = u_x$, se puede aproximar usando las siguientes fórmulas de diferencias finitas:\n",
        "\n",
        "- **Derivada primera hacia adelante o progresiva (forward):**\n",
        "$$\n",
        "u_x \\approx \\frac{u(x+\\Delta x) - u(x)}{\\Delta x}\n",
        "$$\n",
        "- **Derivada primera hacia atrás o regresiva (backward):**\n",
        "$$\n",
        "u_x \\approx \\frac{u(x) - u(x-\\Delta x)}{\\Delta x}\n",
        "$$\n",
        "- **Derivada primera central:**\n",
        "$$\n",
        "u_x \\approx \\frac{u(x+\\Delta x) - u(x-\\Delta x)}{2\\Delta x}\n",
        "$$\n",
        "\n",
        "Y recordemos que otra manera de pensarlo era con el desarrollo de Taylor truncado de la función $u(x)$, de donde obteníamos que el error de truncamiento era del orden de $O(\\Delta x)$ para las fórmulas forward y backward, y de $O((\\Delta x)^2)$ para la fórmula central.\n",
        "\n"
      ],
      "metadata": {
        "id": "rV5FX1MQ1Al9"
      },
      "id": "rV5FX1MQ1Al9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Derivadas segundas\n",
        "\n",
        "La estimación de derivadas segundas es crucial para la resolución numérica de ecuaciones que involucran este tipo de términos. De manera análoga a lo que hicimos para la derivada primera, podemos aproximar la derivada segunda con el cociente incremental, pero ahora de las derivadas primeras:\n",
        "\n",
        "- **Derivada segunda hacia adelante o progresiva (forward):**\n",
        "$$\n",
        "u_{xx}(x) \\approx \\frac{u(x+2\\Delta x) - 2u(x+\\Delta x) + u(x)}{(\\Delta x)^2}\n",
        "$$\n",
        "\n",
        "- **Derivada segunda hacia atrás o regresiva (backward):**\n",
        "$$\n",
        "u_{xx}(x) \\approx \\frac{u(x) - 2u(x-\\Delta x) + u(x-2\\Delta x)}{(\\Delta x)^2}\n",
        "$$\n",
        "- **Derivada segunda central:**\n",
        "$$\n",
        "u_{xx}(x) \\approx \\frac{u(x+\\Delta x) - 2u(x) + u(x-\\Delta x)}{(\\Delta x)^2}\n",
        "$$\n",
        "\n",
        "Estas fórmulas son de orden $O((\\Delta x)^2)$, lo que significa que el error decrece cuadráticamente con el tamaño del paso de tiempo $\\Delta x$.\n",
        "\n",
        "La fórmula más común y sencilla para aproximar la segunda derivada temporal es mediante diferencias finitas centrales.\n",
        "\n"
      ],
      "metadata": {
        "id": "TegovkjB3CQl"
      },
      "id": "TegovkjB3CQl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 1\n",
        "\n",
        "Sea la función $u(x)=sin(x)$, cuál es su derivada segunda? Comparar lo esperado analíticamente con el resultado de calcularla con diferencias finitas centrales."
      ],
      "metadata": {
        "id": "QDMrVb_B261V"
      },
      "id": "QDMrVb_B261V"
    },
    {
      "cell_type": "code",
      "source": [
        "# # # COMPLETAR"
      ],
      "metadata": {
        "id": "QPAEGdHTf-ui"
      },
      "id": "QPAEGdHTf-ui",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrices de Diferenciación\n",
        "<!-- $$\\require{amsmath}$$ -->\n",
        "\n",
        "Supongamos que tenemos un conjunto de valores discretos de una variable $u$. Podemos entonces usar el método de diferencias finitas para aproximar las derivadas utilizando diferencias entre los valores de la variable en puntos discretos de una grilla. Este tipo de estrategia se aplica comúnmente para resolver ecuaciones en dominios discretizados.\n",
        "\n",
        "$$\n",
        "\\begin{matrix}\n",
        "\\bullet && \\dots && \\bullet && \\bullet && \\bullet && \\dots && \\bullet \\\\\n",
        "x_{1} && && x_{i-1} && x_i && x_{i+1} && && x_{N} \\\\\n",
        "\\end{matrix}\n",
        "$$\n",
        "\n",
        "Para implementar la derivada en una grilla de puntos, construimos **matrices de diferenciación**. Estas matrices aplican el operador de derivación a cualquier función $u$ discretizada en una grilla.\n",
        "Para construir las matrices de diferenciación en el método de diferencias finitas, tomemos una grilla uniforme de $N$ puntos en el intervalo $[a, b]$, donde el espaciamiento entre puntos es $h = \\frac{b - a}{N - 1}$. Supongamos que tenemos una variable $u(x)$ evaluada en los puntos $x_1, x_2, \\dots, x_N$, y queremos aproximar las derivadas de $u$ en esos puntos. Las matrices de diferenciación actuarán sobre el vector $\\mathbf{u} = [u(x_1), u(x_2), \\dots, u(x_N)]^\\top$.\n",
        "\n",
        "Por un tema de simplicidad, podemos plantear la siguiente notación $u(x_i)=u_i$, y $u(x_i+h)=u_{i+1}$. Entonces, para el punto $i$, la derivada de $u$, usando por ejemplo la fórmula forward, sería:\n",
        "\n",
        "$$\n",
        "u'_i \\approx \\frac{u_{i+1} - u_i}{h}\n",
        "$$\n",
        "\n",
        "Esto quiere decir que para obtener el vector de derivadas $\\mathbf{u'} = [u_1, u_2, \\dots, u_N]$ podemos resolver de manera recursiva un sistema de ecuaciones como el siguiente:\n",
        "\n",
        "$$\n",
        "\\left\\{\n",
        "\\begin{array}{c}\n",
        "  u'_0 = (u_1 - u_0)/h \\\\\n",
        "  u'_1 = (u_2 - u_1)/h \\\\\n",
        "  \\dots \\\\\n",
        "  u'_{N-1} = (u_N - u_{N-1})/h \\\\\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "Este problema se puede pensar también como un problema de álgebra de matrices, tal que\n",
        "\n",
        "$$\n",
        "\\mathbf{u'} = D \\mathbf{u}^\\top\n",
        "$$\n",
        "\n",
        "Donde la matriz D es una matriz rala de NxN, en la que sólo sobreviven los elementos que me relacionan cada $u'_i$ con combinaciones de $u_{i+1}$, $u_{i}$, $u_{i-1}$. Esto sirve para el cálculo de las derivadas con cualquiera de las 3 fórmulas de diferencias finitas.\n",
        "\n",
        "Entonces, para todos los puntos internos $i = 1, 2, \\dots, N-1$, la matriz de diferencias finitas de primera derivada hacia adelante, $D$, toma la forma:\n",
        "\n",
        "$$\n",
        "D = \\frac{1}{h}\n",
        "\\begin{bmatrix}\n",
        "-1 & 1 & 0 & 0 & \\dots & 0 & 0 \\\\\n",
        "0 & -1 & 1 & 0 & \\dots & 0 & 0 \\\\\n",
        "0 & 0 & -1 & 1 & \\dots & 0 & 0 \\\\\n",
        "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
        "0 & 0 & 0 & 0 & \\dots & -1 & 1 \\\\\n",
        "0 & 0 & 0 & 0 & \\dots & 0 & 0\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Donde la última fila está vacía porque el método forward no puede aplicarse al último punto sin datos adicionales, y queda usualmente definida por las condiciones de contorno.\n",
        "\n",
        "De la misma manera, podemos plantear que la matriz de diferencias finitas de la primera derivada central es:\n",
        "\n",
        "$$\n",
        "D = \\frac{1}{2h}\n",
        "\\begin{bmatrix}\n",
        "0 & 1 & 0 & 0 & \\dots & 0 & 0 & 0 \\\\\n",
        "-1 & 0 & 1 & 0 & \\dots & 0 & 0 & 0 \\\\\n",
        "0 & -1 & 0 & 1 & \\dots & 0 & 0 & 0 \\\\\n",
        "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots \\\\\n",
        "0 & 0 & 0 & 0 & \\dots & -1 & 0 & 1 \\\\\n",
        "0 & 0 & 0 & 0 & \\dots & 0 & -1 & 0\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Para la **segunda derivada** $u''(x)$, podemos usar una aproximación centrada que involucra los puntos $x_{i-1}$, $x_i$, y $x_{i+1}$:\n",
        "\n",
        "$$\n",
        "u''_i \\approx \\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2}\n",
        "$$\n",
        "\n",
        "Entonces, la matriz de diferencias finitas para la segunda derivada es:\n",
        "\n",
        "$$\n",
        "D = \\frac{1}{h^2}\n",
        "\\begin{bmatrix}\n",
        "-2 & 1 & 0 & 0 & \\dots & 0 & 0 & 0 \\\\\n",
        "1 & -2 & 1 & 0 & \\dots & 0 & 0 & 0 \\\\\n",
        "0 & 1 & -2 & 1 & \\dots & 0 & 0 & 0 \\\\\n",
        "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots \\\\\n",
        "0 & 0 & 0 & 0 & \\dots & 1 & -2 & 1 \\\\\n",
        "0 & 0 & 0 & 0 & \\dots & 0 & 1 & -2\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "De esta manera, en una ecuación diferencial, el operador diferencial $\\mathcal{D}[u(x)]$ se puede reemplazar por una matriz de diferenciación $\\mathbf{D}$ que aplica las diferencias finitas\n",
        "\n",
        "$$\n",
        "\\mathcal{D}[u(x)] \\approx \\mathbf{D} \\cdot \\mathbf{u}.\n",
        "$$\n",
        "\n",
        "Al discretizar el problema, obtenemos un sistema de ecuaciones matricial de la forma\n",
        "\n",
        "$$\n",
        "\\mathbf{D} \\cdot \\mathbf{u} = \\mathbf{g},\n",
        "$$\n",
        "\n",
        "Donde $\\mathbf{D}$ es la matriz de diferenciación; $\\mathbf{u}$ es el vector desconocido que queremos calcular (los valores de $u(x)$ en los puntos de la grilla); y $\\mathbf{g}$ representa el lado derecho de la ecuación diferencial, evaluado en cada punto de la grilla ($g(x_i)$).\n"
      ],
      "metadata": {
        "id": "MkZqrR15fdWK"
      },
      "id": "MkZqrR15fdWK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Condiciones de contorno\n",
        "\n",
        "Las **condiciones de contorno** especifican el comportamiento de la solución en los bordes del dominio (por ejemplo, en los puntos $x_1$ y $x_N$ de una grilla de $N$ puntos). Estas condiciones son esenciales para completar el sistema de ecuaciones diferenciales y afectan directamente las primeras y últimas filas de las matrices de diferenciación. Así, la **matriz de diferenciación modificada** no sólo cumple las ecuaciones haciendo una aproximación de las derivadas, si no que también garantiza una solución consistente con las condiciones de contorno dadas.\n",
        "\n",
        "Existen varios tipos comunes de condiciones de contorno:\n",
        "\n",
        "#### 1. Condiciones de Dirichlet\n",
        "\n",
        "Las **condiciones de Dirichlet** fijan el valor de la función en los extremos del dominio. Por ejemplo, si queremos que $u(x_1) = \\alpha$ y $u(x_N) = \\beta$, simplemente se imponen estos valores en las posiciones correspondientes de $\\mathbf{u}$:\n",
        "$$\n",
        "u_1 = \\alpha, \\quad u_N = \\beta\n",
        "$$\n",
        "\n",
        "Para implementar estas condiciones en la matriz, reemplazamos la primera y última ecuación en el sistema por $u_1 = \\alpha$ y $u_N = \\beta$, eliminando la necesidad de calcular derivadas en esos puntos.\n",
        "\n",
        "Por ejemplo, si estamos trabajando con una matriz para una segunda derivada $D_2$, para $N = 5$, la matriz original sería:\n",
        "\n",
        "$$\n",
        "D_2 = \\frac{1}{h^2}\n",
        "\\begin{bmatrix}\n",
        "-2 & 1 & 0 & 0 & 0 \\\\\n",
        "1 & -2 & 1 & 0 & 0 \\\\\n",
        "0 & 1 & -2 & 1 & 0 \\\\\n",
        "0 & 0 & 1 & -2 & 1 \\\\\n",
        "0 & 0 & 0 & 1 & -2\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Las condiciones de contorno de Dirichlet ($u(x_1) = \\alpha, u(x_5) = \\beta $), fijan el valor de la variable en los extremos. En la matriz de diferenciación, la primera y última filas se reemplazan por filas que imponen estas condiciones directamente. Esto equivale a garantizar que $u(x_1) = \\alpha$ y $u(x_N) = \\beta$ en el sistema lineal. De esta manera, modificamos la primera y última filas para imponer estas restricciones:\n",
        "\n",
        "$$\n",
        "D_2 = \\frac{1}{h^2}\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 & 0 & 0 \\\\\n",
        "1 & -2 & 1 & 0 & 0 \\\\\n",
        "0 & 1 & -2 & 1 & 0 \\\\\n",
        "0 & 0 & 1 & -2 & 1 \\\\\n",
        "0 & 0 & 0 & 0 & 1\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Además, el vector del lado derecho del sistema que describe la ecuación diferencial debe ajustarse para incluir los valores $\\alpha$ y $\\beta$, por ejemplo:\n",
        "\n",
        "$$\n",
        "\\mathbf{g} = \\begin{bmatrix}\n",
        "\\alpha \\\\\n",
        "g(x_2) \\\\\n",
        "g(x_3) \\\\\n",
        "g(x_4) \\\\\n",
        "\\beta\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "\n",
        "#### 2. Condiciones de Neumann\n",
        "\n",
        "Las **condiciones de Neumann** especifican el valor de la derivada en los extremos. Por ejemplo, si $u'(x_1) = \\gamma$ y $u'(x_N) = \\delta$, la derivada en los extremos se puede aproximar usando una fórmula de diferencias finitas.\n",
        "\n",
        "Para $u'(x_1) = \\gamma$, se puede usar una diferencia hacia adelante:\n",
        "\n",
        "$$\n",
        "u'_1 \\approx \\frac{u_2 - u_1}{h} = \\gamma \\Rightarrow u_2 = u_1 + h \\gamma\n",
        "$$\n",
        "\n",
        "Para $u'(x_N) = \\delta$, se usa una diferencia hacia atrás:\n",
        "\n",
        "$$\n",
        "u'_N \\approx \\frac{u_N - u_{N-1}}{h} = \\delta \\Rightarrow u_{N-1} = u_N - h \\delta\n",
        "$$\n",
        "\n",
        "Esto afecta la matriz de diferenciación al cambiar las primeras y últimas filas para reflejar estas derivadas en lugar de las derivadas internas.\n",
        "\n",
        "Cuando tengo condiciones de borde periódicas, la relación es $u(a) = u(b)$. Esto significa que el último punto de la grilla se conecta al primero, permitiéndonos calcular derivadas en todos los nodos sin excepciones. Para implementar esta condición hacemos lo mismo que antes, ajustamos los valores de la primera y última fila en la matriz de diferenciación.\n"
      ],
      "metadata": {
        "id": "IxwIwQYLfdTM"
      },
      "id": "IxwIwQYLfdTM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 2\n",
        "\n",
        "2.1. Implementar funciones que calculen matrices de diferenciación para calcular la derivada primera con los 3 métodos de diferencias finitas sobre un subconjunto adecuado de los nodos de una grilla de un cierto intervalo $[a,b]$. Para esto, explore la construcción de matrices ralas con elementos diagonales, o cerca de la diagonal con la función `np.diag` de Numpy.\n",
        "\n",
        "2.2. Pruebe estas funciones por ejemplo para obtener la derivada primera de la función $f(x)=sin(x)$.\n",
        "\n",
        "2.3. Replantee el problema para que la implementación sea sobre todos los nodos de la grilla y asumiendo condiciones de borde periódicas $u(a)=u(b)$.\n"
      ],
      "metadata": {
        "id": "0KVo_4AETcru"
      },
      "id": "0KVo_4AETcru"
    },
    {
      "cell_type": "code",
      "source": [
        "# # # COMPLETAR"
      ],
      "metadata": {
        "id": "BbDlmplLfew7"
      },
      "id": "BbDlmplLfew7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo**\n",
        "\n",
        "Sea una función $u(x)$, resolvamos la siguiente ecuación diferencial con diferencias finitas\n",
        "\n",
        "$$\n",
        "u'' = x^2 - 2 \\\\\n",
        "$$\n",
        "\n",
        "Para condiciones de contorno $u(0) = 0$ y $u(3) = 2$\n"
      ],
      "metadata": {
        "id": "2fCTzBqhKALn"
      },
      "id": "2fCTzBqhKALn"
    },
    {
      "cell_type": "code",
      "source": [
        "def u_pp(x):\n",
        "    return x**2 - 2\n",
        "\n",
        "x1 = 0\n",
        "x2 = 3\n",
        "u1 = 0\n",
        "u2 = 2\n",
        "\n",
        "N = 100\n",
        "x = np.linspace(x1, x2, N+1)\n",
        "dx = x[1] - x[0]\n",
        "\n",
        "M = np.diag(-2*np.ones(N+1), 0) + np.diag(np.ones(N), 1) + np.diag(np.ones(N), -1)\n",
        "M[0, 0] = 1\n",
        "M[0, 1] = 0\n",
        "M[-1, -1] = 1\n",
        "M[-1, -2] = 0\n",
        "\n",
        "g = (u_pp(x))*dx**2\n",
        "g[0] = u1\n",
        "g[-1] = u2\n",
        "\n",
        "M_inv = np.linalg.inv(M)\n",
        "f = np.matmul(M_inv, g)\n",
        "# f = M_inv @ g\n",
        "# f = np.linalg.solve(M, g)\n",
        "plt.plot(x, f)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qxvpeme7Jqit"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Qxvpeme7Jqit"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 3\n",
        "\n",
        "Considere ahora la ecuación para una función $u(x)$, con sus condiciones de contorno\n",
        "\n",
        "$$\n",
        "u'' = 2 \\\\\n",
        "u(0) = 0 \\\\\n",
        "u(1) = 0 \\\\\n",
        "$$\n",
        "\n",
        "Piense a priori si se le ocurre cuál podría ser una solución, si tuviera que resolver analíticamente, pero sin hacerlo. Resuelva ahora con el método de diferencias finitas como el usado en el ejemplo anterior. [Hint: puede tener problemas con la dimensión de la función u_pp evaluada en x si no la define correctamente. Asegúrese que la salida de esta función tenga las mismas dimensiones que x, generando el vector de salida para que las tenga]\n"
      ],
      "metadata": {
        "id": "eYbA9gU1Z3HN"
      },
      "id": "eYbA9gU1Z3HN"
    },
    {
      "cell_type": "code",
      "source": [
        "# # # COMPLETAR"
      ],
      "metadata": {
        "id": "IK4NHs-XJqgV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "IK4NHs-XJqgV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 4\n",
        "\n",
        "Elijamos ahora un problema del eje temático 1, de ODEs. Podemos intentar resolverlo con el método de diferencias finitas hacia adelante en una grilla de 100 puntos, con paso $h=0.01$, para una condición inicial. Busquen un problema y la manera de resolverlo para una condición inicial y comparen con lo esperado. Cómo tendríamos que plantear la matriz de diferenciación para que no sólo contenga la aproximación de la derivada, si no que también incorpore tanto términos que tengan dependencia con la variables como la condición inicial?"
      ],
      "metadata": {
        "id": "uNQ_osCaTqTH"
      },
      "id": "uNQ_osCaTqTH"
    },
    {
      "cell_type": "code",
      "source": [
        "# # # COMPLETAR"
      ],
      "metadata": {
        "id": "1vtCMtKTjjuV"
      },
      "id": "1vtCMtKTjjuV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Ecuaciones en derivadas parciales (PDEs)\n",
        "\n",
        "Las PDEs involucran derivadas de una función con respecto a más de una variable independiente, a diferencia de las ODEs que tenían una única variable independiente. Entonces vamos a tener un campo escalar $u(x,t)$, que puede depender por ejemplo del tiempo y de una variable espacial. Para describir las derivadas parciales de $u(x,t)$ muchas veces se usa la siguiente notación $\\frac{\\partial u(x,t)}{\\partial x} = u_x$.\n",
        "\n",
        "Anteriormente, teníamos funciones univariadas, por lo que necesitábamos discretizar las derivadas sólo en esa variable, que podía ser por ejemplo tiempo o espacio. Cuando tenemos funciones multivariadas ahora tenemos derivadas tanto en el espacio como en el tiempo, por lo que necesitamos discretizar con respecto a ambas variables.\n",
        "\n",
        "Podemos entonces pensar en un gráfico de *espacio-tiempo*, donde las coordenadas en la dirección vertical representan el avance en el tiempo (por ejemplo, de $t^n$ a $t^{n+1}$) y las coordenadas en la dirección horizontal se mueven en el espacio: los puntos consecutivos son $x_{i-1}$, $x_i$ y $x_{i+1}$. Esto crea una cuadrícula donde un punto tiene un índice tanto temporal como espacial. Aquí hay una representación gráfica de la cuadrícula espacio-temporal:\n",
        "\n",
        "$$\n",
        "\\begin{matrix}\n",
        "t^{n+1} & \\rightarrow & \\bullet && \\bullet && \\bullet \\\\\n",
        "t^n & \\rightarrow & \\bullet && \\bullet && \\bullet \\\\\n",
        "& & x_{i-1} && x_i && x_{i+1}\n",
        "\\end{matrix}\n",
        "$$\n",
        "\n",
        "Para la solución numérica de $u(x,t)$, usaremos subíndices para indicar la posición espacial, como $u_i$, y superíndices para indicar el instante temporal, como $u^n$. Luego etiquetaríamos la solución en el punto medio superior de la cuadrícula anterior de la siguiente manera:\n",
        "$u^{n+1}_{i}$.\n",
        "\n",
        "Cada punto de la cuadrícula a continuación tiene un índice $i$, que corresponde a la posición espacial y aumenta hacia la derecha, y un índice $n$, que corresponde al instante temporal y aumenta hacia arriba. Un segmento de cuadrícula pequeño tendría los siguientes valores de la solución numérica en cada punto:\n",
        "\n",
        "$$\n",
        "\\begin{matrix}\n",
        "& &\\bullet & & \\bullet & & \\bullet \\\\\n",
        "& &u^{n+1}_{i-1} & & u^{n+1}_i & & u^{n+1}_{i+1} \\\\\n",
        "& &\\bullet & & \\bullet & & \\bullet \\\\\n",
        "& &u^n_{i-1} & & u^n_i & & u^n_{i+1} \\\\\n",
        "& &\\bullet & & \\bullet & & \\bullet \\\\\n",
        "& &u^{n-1}_{i-1} & & u^{n-1}_i & & u^{n-1}_{i+1} \\\\\n",
        "\\end{matrix}\n",
        "$$\n",
        "\n",
        "Otra forma de explicar nuestra cuadrícula de discretización es decir que está construida con pasos constantes en el tiempo y el espacio, $\\Delta t$ y $\\Delta x$, de la siguiente manera:\n",
        "\n",
        "$$\n",
        "\\begin{eqnarray}\n",
        "x_i &=& i\\, \\Delta x \\quad \\text{y} \\quad t^n= n\\, \\Delta t \\nonumber \\\\\n",
        "u_i^n &=& u(i\\, \\Delta x, n\\, \\Delta t)\n",
        "\\end{eqnarray}\n",
        "$$"
      ],
      "metadata": {
        "id": "zfL2bmEoP4oG"
      },
      "id": "zfL2bmEoP4oG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métodos explícitos e implícitos\n",
        "\n",
        "El método explícito y el método implícito son métodos de análisis numérico que se utilizan para resolver una ecuación diferencial dependiente del tiempo. Los términos **explícito** e **implícito** describen cómo se avanza en el tiempo en la solución numérica de una PDE, independientemente del método usado para aproximar derivadas. Así que, una vez que hemos aproximado las derivadas usando diferencias finitas, podemos elegir entre un esquema explícito o implícito para resolver la ecuación en el tiempo.\n",
        "\n",
        "- **Método Explícito**: Calcula los valores futuros de la solución en función de los valores actuales, lo cual permite resolver directamente la ecuación en cada paso de tiempo sin resolver un sistema de ecuaciones.\n",
        "\n",
        "- **Método Implícito**: Calcula los valores futuros de la solución en función de los valores actuales pero también de valores futuros. Esto hace que sea necesario resolver un sistema de ecuaciones en cada paso de tiempo para encontrar los valores en el siguiente paso temporal.\n"
      ],
      "metadata": {
        "id": "kxoSMm3K6A34"
      },
      "id": "kxoSMm3K6A34"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Diferencia entre métodos explícitos e implícitos\n",
        "\n",
        "Los **métodos explícitos** son simples de implementar, pero su estabilidad es baja y requiere del uso de pasos chicos para evitar la divergencia. En problemas de difusión, por ejemplo, los métodos explícitos requieren que $\\Delta t$ sea particularmente muy chico para asegurar la estabilidad.\n",
        "\n",
        "Los **métodos implícitos** son altamente estables y convergen si se establecen los parámetros adecuados. Debido a su estabilidad, permiten mayores pasos de tiempo sin comprometer la precisión, por lo que pueden ser muy útiles para resolver ecuaciones que implican evoluciones extendidas en la variable tiempo. No obstante, requieren resolver un sistema de ecuaciones en cada paso de tiempo, lo cual puede ser computacionalmente muy costoso.\n",
        "\n",
        "En la aplicación a PDEs, cada método tiene sus limitaciones y se ajusta mejor a ciertas ecuaciones o tipos de problemas:\n",
        "\n",
        "- **Ecuaciones de Difusión** (como la del calor): Se pueden resolver tanto con métodos explícitos (aunque requieren pasos de tiempo pequeños para ser estables) como con métodos implícitos.\n",
        "\n",
        "- **Ecuaciones de Onda**: En este caso, los métodos explícitos de diferencias finitas funcionan bien porque las soluciones suelen ser estables para pasos de tiempo razonables, aunque también se pueden usar métodos implícitos.\n",
        "\n",
        "- **Ecuación de Poisson o Laplace**: Estas son ecuaciones elípticas, por lo que los métodos implícitos son necesarios. Inclusive, el método de diferencias finitas funciona mejor para geometrías simples. Para otros casos es ya directamente recomendable explorar otras estrategias.\n"
      ],
      "metadata": {
        "id": "uk65K0TQ5umi"
      },
      "id": "uk65K0TQ5umi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo**\n",
        "\n",
        "Para ilustrar cómo el método de diferencias finitas se combina con los métodos explícitos o implícitos, consideremos la **ecuación de difusión**:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}\n",
        "$$\n",
        "\n",
        "**Método de Diferencias Finitas en Esquema Explícito**: Si aplicamos diferencias finitas en el tiempo y en el espacio, podemos escribir:\n",
        "\n",
        "$$\n",
        "\\frac{u(x, t + \\Delta t) - u(x, t)}{\\Delta t} = \\alpha \\frac{u(x + \\Delta x, t) - 2u(x, t) + u(x - \\Delta x, t)}{(\\Delta x)^2}\n",
        "$$\n",
        "\n",
        "Resolviendo para $u(x, t + \\Delta t)$, obtenemos una expresión en función de los valores actuales, lo cual constituye un esquema explícito.\n",
        "\n",
        "**Método de Diferencias Finitas en Esquema Implícito**: Si, en cambio, aplicamos diferencias finitas de modo que los valores en el lado derecho de la ecuación están evaluados en $t + \\Delta t$, obtenemos un sistema de ecuaciones para $u(x, t + \\Delta t)$, lo cual requiere resolver un sistema de ecuaciones para cada paso de tiempo.\n"
      ],
      "metadata": {
        "id": "Tz71SboUU2U6"
      },
      "id": "Tz71SboUU2U6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Aplicación a PDEs\n",
        "\n",
        "## Ecuación de convección lineal 1D\n",
        "\n",
        "La ecuación de convección lineal unidimensional es un caso bastante simple para estudiar la resolución numérica de ecuaciones en derivadas parciales. Se describe a partir de la siguiente expresión:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\frac{\\partial u}{\\partial t} + c \\frac{\\partial u}{\\partial x} = 0\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "La ecuación representa una *onda* que se propaga con velocidad $c$ en la dirección $x$, sin cambiar de forma. Por esa razón, a veces se la llama *ecuación de onda unidireccional* (a veces también *ecuación de advección*).\n",
        "\n",
        "Con una condición inicial $u(x,0)=u_0(x)$, la ecuación tiene una solución exacta dada por:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "u(x,t)=u_0(x-ct)\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "Podemos ver que es solución de la ecuación tomando la derivada respecto del tiempo y del espacio y verificando que la ecuación se cumple.\n",
        "\n",
        "De la solución exacta se pueden observar que su forma no cambia, siendo siempre la misma que la onda inicial, $u_0$, solo desplazada en la dirección $x$.\n"
      ],
      "metadata": {
        "id": "l_I02iX8Onye"
      },
      "id": "l_I02iX8Onye"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos cómo discretizar la ecuación de convección lineal unidimensional tanto en el espacio como en el tiempo. Por definición, la derivada parcial con respecto al tiempo cambia solo con el tiempo y no con el espacio; su forma discretizada cambia solo los $n$ índices. De manera similar, la derivada parcial con respecto a $x$ cambia con el espacio, no con el tiempo, y solo se ven afectados los $i$ índices.\n",
        "\n",
        "Discretizaremos la coordenada espacial $x$ en puntos indexados de $i=0$ a $N$, y luego avanzaremos en intervalos de tiempo discretos de tamaño $\\Delta t$.\n",
        "\n",
        "A partir de la definición de derivada (y simplemente eliminando el límite), sabemos que para $\\Delta x$ suficientemente pequeño:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\frac{\\partial u}{\\partial x}\\approx \\frac{u(x+\\Delta x)-u(x)}{\\Delta x}\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "Esta fórmula se puede aplicar en cualquier punto $x_i$. Pero tenga en cuenta que no es la única forma en que podemos estimar la derivada. La interpretación geométrica de la primera derivada $\\partial u/ \\partial x$ en cualquier punto es que representa la pendiente de la tangente a la curva $u(x)$. En el esquema a continuación, mostramos una línea de pendiente en $x_i$ y la marcamos como \"exacta\". Si la fórmula escrita anteriormente se aplica en $x_i$, aproxima la derivada utilizando el siguiente punto de la cuadrícula espacial: entonces se denomina fórmula de _diferencia hacia adelante_.\n",
        "\n",
        "Pero, como se muestra en el esquema a continuación, también podríamos estimar la derivada espacial utilizando el punto detrás de $x_i$, en cuyo caso se llama _diferencia hacia atrás_. Incluso podríamos utilizar los dos puntos a cada lado de $x_i$ y obtener lo que se llama una _diferencia central_ (pero en ese caso el denominador sería $2\\Delta x$)."
      ],
      "metadata": {
        "id": "8dTEe0K7t-vO"
      },
      "id": "8dTEe0K7t-vO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 5\n",
        "\n",
        "Resuelvan la ecuación de convección lineal 1D con una condición inicial de *onda cuadrada*, definida de la siguiente manera:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "u(x,0)=\\begin{cases}2 & \\text{donde } 0.5\\leq x \\leq 1,\\\\\n",
        "1 & \\text{en cualquier otro lugar en } (0, 2)\n",
        "\\end{cases}\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "Considere como condición de contorno que sea $u=1$ en $x=0$. Nuestro dominio espacial para la solución numérica solo cubrirá el rango $x\\in (0, 2)$.\n",
        "\n",
        "Para esto creen una cuadrícula de puntos espaciados uniformemente dentro de nuestro dominio espacial. Defina también un paso en el tiempo, una cantidad de pasos, y un valor para la velocidad de la onda. Por simplicidad, use que $c=1$.\n",
        "\n",
        "Qué observa qué pasa con la onda cuadrada?"
      ],
      "metadata": {
        "id": "1tnPLqJHuPyk"
      },
      "id": "1tnPLqJHuPyk"
    },
    {
      "cell_type": "code",
      "source": [
        "# # # COMPLETAR"
      ],
      "metadata": {
        "id": "ayWkZM3nhf6E"
      },
      "id": "ayWkZM3nhf6E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i1fWaUCTvnuA"
      },
      "id": "i1fWaUCTvnuA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}